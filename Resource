etat de l'art du projet :1. La Détection d'Émotions Faciales (Computer Vision)
Vous devez expliquer l'évolution des technologies pour reconnaître un visage et une émotion :

Les méthodes classiques (Ancien) : Avant, on utilisait des filtres manuels ou des algorithmes géométriques (calculer la distance entre les yeux et la bouche). C'était peu précis.
L'ère du Deep Learning (Moderne) : L'arrivée des réseaux de neurones convolutifs (CNN) comme ResNet ou MobileNet qui ont révolutionné la précision.
Le "State of the Art" actuel (Votre projet) : Aujourd'hui, on utilise des Vision Transformers (ViT) (comme le modèle dima806 que vous utilisez via HuggingFace). Ces modèles "regardent" l'image globalement et sont très performants.
Ce que vous dites dans le rapport : "Nous utilisons une approche basée sur le Deep Learning moderne (Transformers) plutôt que de simples calculs géométriques, car cela offre une meilleure précision sur les émotions subtiles."
2. L'Intelligence Artificielle Générative (NLP)
C'est la partie qui génère les conseils.

Les méthodes classiques : Des systèmes basés sur des règles (ex: if emotion == 'sad' print "Sois heureux"). C'est rigide et répétitif.
Le "State of the Art" actuel : Les LLM (Large Language Models) comme GPT-4 ou Llama. Ils comprennent le contexte et génèrent du texte humain et nuancé.
Votre spécificité (Edge AI / SLM) : Vous utilisez TinyLlama, qui est un Small Language Model. C'est une tendance très actuelle : faire tourner des IA puissantes localement (sur la machine de l'utilisateur) pour garantir la confidentialité des données (pas d'envoi vers le cloud) et réduire les coûts.
3. L'Architecture Technique
Backend & API : L'utilisation de FastAPI (Python) est l'état de l'art pour servir des modèles d'IA car c'est asynchrone et très rapide, contrairement à des frameworks plus anciens comme Flask (plus lent) ou Django (trop lourd).



 1. Solutions Cloud (API Commerciales)
Ces solutions sont très puissantes mais nécessitent une connexion internet et sont souvent payantes. Elles fonctionnent comme votre ancien système (envoi d'image -> réception du résultat).

Azure AI Vision (Microsoft)
Description : Une des solutions les plus robustes du marché. Elle détecte les visages et peut analyser des attributs comme l'émotion, l'âge, ou le port de lunettes.
Lien : Documentation Azure Face API
Note : Microsoft a récemment limité l'accès à la détection d'émotions pour des raisons éthiques, il faut souvent une demande spéciale.
Amazon Rekognition
Description : Le service de vision par ordinateur d'AWS. Il offre une analyse faciale très détaillée incluant une gamme d'émotions avec un score de confiance (exactement comme votre projet).
Lien : Documentation Amazon Rekognition - Face Analysis
Google Cloud Vision API
Description : L'API de Google détecte les visages et donne une probabilité pour des émotions spécifiques (joie, tristesse, colère, surprise).
Lien : Documentation Google Cloud Vision - Face Detection
Face++ (Megvii)
Description : Une entreprise chinoise leader dans la reconnaissance faciale. Leur API est très précise pour les micro-expressions.
Lien : Documentation Face++ Detect API
2. Solutions Web / Navigateur (Client-Side)
Ces solutions se rapprochent de votre approche "locale" car elles tournent directement dans le navigateur de l'utilisateur (via JavaScript), sans envoyer l'image à un serveur.

face-api.js
Description : C'est la bibliothèque JavaScript la plus populaire pour faire ça dans un navigateur. Elle est basée sur TensorFlow.js. Elle permet de détecter les visages et les expressions (happy, sad, angry, etc.) en temps réel via la webcam.
Lien : Documentation & Démo face-api.js
GitHub : Repo face-api.js
Visage Technologies (VisageSDK)
Description : Une solution professionnelle très légère conçue pour tourner sur des appareils mobiles et le web (HTML5). Utilisée dans le marketing et l'automobile.
Lien : Visage Technologies - Face Analysis
